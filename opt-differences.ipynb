{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There needs to be a folder with folder name as declared in data_folder inside the folder where\n",
    "# this script is located.\n",
    "# Inside this folder there needs to be a folder with dataset name. \n",
    "# Inside the folder with dataset name there needs to be a folder with name sigma_length\n",
    "# Inside this folder there needs to be a file for each file of the dataset with the \n",
    "# costs of the optimal algorithm and the approximation algorithm for each value of d\n",
    "# for the value of sigma_length\n",
    "\n",
    "data_folder = \"./opt-differences/\"\n",
    "sigma_length = 5\n",
    "results_folder = \"./opt-differences/results/\"\n",
    "dataset_name = \"canterbury\"\n",
    "ds = [1, 2, 3, 4, 5, 6, 10, 20, 50, 100]\n",
    "\n",
    "if (dataset_name == \"canterbury\"):\n",
    "    dataset_file_names = [\"alice29.txt\", \"asyoulik.txt\", \"cp.html\", \"fields.c\", \"grammar.lsp\", \\\n",
    "                         \"kennedy.xls\", \"lcet10.txt\", \"ptt5\", \"sum\", \"plrabn12.txt\", \"xargs.1\"]\n",
    "    dataset_file_lengths = [152089, 125179, 24603, 11150, 3721, 1029744, 426754, 513216, 38240, 481861, 4227]\n",
    "    dataset_file_unique = [74, 68, 86, 90, 76, 256, 84, 159, 255, 81, 74]\n",
    "elif (dataset_name == \"calgary\"):\n",
    "    dataset_file_names = [\"bib\", \"book1\", \"book2\", \"geo\", \"news\", \"obj1\", \"obj2\", \"paper1\", \"paper2\", \\\n",
    "                         \"paper3\", \"paper4\", \"paper5\", \"paper6\", \"pic\", \"progc\", \"progl\", \"progp\", \"trans\"]\n",
    "    dataset_file_lengths = [111261, 768771, 610856, 102400, 377109, 21504, 246814, 53161, 82199, 46526, \\\n",
    "                           13286, 11954, 38105, 513216, 39611, 71646, 49379, 93695]\n",
    "    dataset_file_unique = [81, 82, 96, 256, 98, 256, 256, 95, 91, 84, 80, 91, 93, 159, 92, 87, 89, 99]\n",
    "elif (dataset_name == \"large\"):\n",
    "    dataset_file_names = [\"bible.txt\", \"world192.txt\", \"E.coli\"]\n",
    "    dataset_file_lengths = [4047392, 2473400, 4638690]\n",
    "    dataset_file_unique = [63, 94, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files():\n",
    "    files = []\n",
    "    for filename in dataset_file_names:\n",
    "        file_path = data_folder + dataset_name + \"/\" + str(sigma_length) + \"/\" + filename\n",
    "        file = open(file_path, 'r').read()\n",
    "        files.append(file)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_results(files):\n",
    "    all_results = []\n",
    "    for file in files:\n",
    "        all_results_file = []\n",
    "        for d in ds:\n",
    "            regex = \"\\n\" + str(d) + \"\\t(\\d*)\\t(\\d*)\\t(-?\\d*)\"\n",
    "            matchobj = re.findall(regex, file, flags=0)\n",
    "            opt_costs = [int(tup[0]) for tup in matchobj]\n",
    "            pairwise_costs = [int(tup[1]) for tup in matchobj]\n",
    "    #         all_results_file.append([opt_costs, pairwise_costs])\n",
    "            all_results_file.append([sum(opt_costs), sum(pairwise_costs)])\n",
    "        all_results.append(all_results_file)\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results():\n",
    "    files = read_files()\n",
    "    all_results = calc_results(files)\n",
    "    for i, file_results in enumerate(all_results):\n",
    "        print(dataset_file_names[i] + \" & \", end=' ')\n",
    "        for d_results in file_results:\n",
    "            print(str(round((d_results[0] - d_results[1])/d_results[0] * 100, 2)) + \" & \", end=' ')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_lengths ():\n",
    "    lengths_averages = []\n",
    "    sigma_lengths = [3, 4, 5]\n",
    "    for filename in dataset_file_names:\n",
    "        length_avg_file = []\n",
    "        for sig_length in sigma_lengths:\n",
    "            file_path = data_folder + dataset_name + \"/\" + str(sig_length) + \"/\" + filename\n",
    "            file = open(file_path, 'r').read()\n",
    "            \n",
    "            regex = \"Sigma length: (\\d*)\"\n",
    "            matchobj = re.findall(regex, file, flags=0)\n",
    "            lengths = [int(elem) for elem in matchobj]\n",
    "            length_avg_file.append(np.average(lengths))\n",
    "        lengths_averages.append(length_avg_file)\n",
    "    return lengths_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_lengths(lengths_averages):\n",
    "    for i, file_name in enumerate(dataset_file_names):\n",
    "        print(file_name + \" & \" + str(dataset_file_lengths[i]) + \" & \" + str(dataset_file_unique[i]) + \" & \", end = ' ')\n",
    "        for length_avg in lengths_averages[i]:\n",
    "            print(str(int(length_avg)) + \" & \", end = ' ')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints the differences between the approximation algorithm and the optimal algorithm in percentage\n",
    "print_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
